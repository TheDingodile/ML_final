`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.
Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use
`config.hidden_activation` if you want to override this behaviour.
See https://github.com/huggingface/transformers/pull/29402 for more details.
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.17it/s]
You're using a GemmaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
Is there any occurrence of anatomical findings in the left hilar structures?
['yes']
('No',)
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.47it/s]
Is there any occurrence of anatomical findings in the left hilar structures?
['yes']
You're using a GemmaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
('No',)
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.20it/s]
Is there any occurrence of anatomical findings in the left hilar structures?
['yes']
You're using a GemmaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
('No',)
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.16it/s]
Is there any occurrence of anatomical findings in the left hilar structures?
['yes']
You're using a GemmaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]

Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.16it/s]
You're using a GemmaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
Is there any occurrence of anatomical findings in the left hilar structures?
['yes']
('No',)
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.16it/s]
You're using a GemmaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
Is there any occurrence of anatomical findings in the left hilar structures?
['yes']
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.45it/s]
('No',)
You're using a GemmaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
Is there any occurrence of anatomical findings in the left hilar structures?
['yes']
('No',)
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.44it/s]
You're using a GemmaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
Is there any occurrence of anatomical findings in the left hilar structures?
['yes']
('No',)
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.19it/s]
You're using a GemmaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
Is there any occurrence of anatomical findings in the left hilar structures?
['yes']
('No',)
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.17it/s]
Is there any occurrence of anatomical findings in the left hilar structures?
['yes']
You're using a GemmaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
('No',)
```